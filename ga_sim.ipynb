{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## ga_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jn is intended to create simulations of dwarf galaxies and globular clusters using as field stars the catalog of DES. These simulations will be later copied to gawa jn, a pipeline to detect stellar systems with field's stars. In principle this pipeline read a table in data base with g and r magnitudes, subtract the extinction in each band, and randomize the positions in RA and DEC in order to avoid stellar systems in the FoV. The star clusters are inserted later, centered in each HP pixel with specific nside.\n",
    "\n",
    "To complete all the steps you just have to run all the cells below in sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, install the packages not available in the image via terminal. Restart the kernel and so you can run the cell bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import healpy as hp\n",
    "import astropy.io.fits as fits\n",
    "from astropy.table import Table\n",
    "from astropy.io.fits import getdata\n",
    "import sqlalchemy\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import parsl\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.configs.local_threads import config\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from ga_sim import (\n",
    "    make_footprint,\n",
    "    faker,\n",
    "    join_cat,\n",
    "    write_sim_clus_features,\n",
    "    download_iso,\n",
    "    read_cat,\n",
    "    gen_clus_file,\n",
    "    read_error,\n",
    "    clus_file_results,\n",
    "    join_cats_clean,\n",
    "    split_files,\n",
    "    clean_input_cat,\n",
    "    clean_input_cat_dist\n",
    ")\n",
    "\n",
    "parsl.clear()\n",
    "parsl.load(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the items of the configuration for field stars and simulations. A small description follows as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main settings:\n",
    "confg = \"ga_sim.json\"\n",
    "\n",
    "# read config file\n",
    "with open(confg) as fstream:\n",
    "    param = json.load(fstream)\n",
    "\n",
    "age_simulation = 1.0e10  # in years\n",
    "Z_simulation = 0.001  # Assuming Z_sun = 0.0152\n",
    "\n",
    "# Diretório para os resultados\n",
    "os.system(\"mkdir -p \" + param['results_path'])\n",
    "\n",
    "# Reading reddening files\n",
    "hdu_ngp = fits.open(\"sample_data/SFD_dust_4096_ngp.fits\", memmap=True)\n",
    "ngp = hdu_ngp[0].data\n",
    "\n",
    "hdu_sgp = fits.open(\"sample_data/SFD_dust_4096_sgp.fits\", memmap=True)\n",
    "sgp = hdu_sgp[0].data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the isochrone table with the last improvements from Padova.\n",
    "Printing age and metalicity of isochrone downloaded. Try one more time in case of problems. Sometimes there is a problem with the connection to Padova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_iso(param['padova_version_code'], param['survey'], Z_simulation,\n",
    "             age_simulation, param['av_simulation'], param['file_iso'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking age and metalicity of the isochrone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading [M/H], log_age, mini, g\n",
    "iso_info = np.loadtxt(param['file_iso'], usecols=(1, 2, 3, 26), unpack=True)\n",
    "FeH_iso = iso_info[0][0]\n",
    "logAge_iso = iso_info[1][0]\n",
    "m_ini_iso = iso_info[2]\n",
    "g_iso = iso_info[3]\n",
    "\n",
    "print('[Fe/H]={:.2f}, Age={:.2f} Gyr'.format(FeH_iso, 10**(logAge_iso-9)))\n",
    "\n",
    "mM_mean = (param['mM_max'] + param['mM_min']) / 2.\n",
    "print(np.max(m_ini_iso[g_iso + mM_mean < param['mmax']]))\n",
    "mean_mass = (np.min(m_ini_iso[g_iso + mM_mean < param['mmax']]) +\n",
    "             np.max(m_ini_iso[g_iso + mM_mean < param['mmax']])) / 2.\n",
    "\n",
    "print('Mean mass (M_sun): {:.2f}'.format(mean_mass))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpx_ftp = make_footprint(param['ra_min'], param['ra_max'], param['dec_min'], param['dec_max'],\n",
    "                         param['nside_ftp'], output_path=param['results_path'])\n",
    "print(len(hpx_ftp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the catalog and writing as a fits file (to avoid read from the DB many times in the case the same catalog will be used multiple times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RA, DEC, MAG_G, MAGERR_G, MAG_R, MAGERR_R = read_cat(\n",
    "    param['vac_ga'], param['ra_min'], param['ra_max'], param['dec_min'], param['dec_max'],\n",
    "    param['mmin'], param['mmax'], param['cmin'], param['cmax'],\n",
    "    \"DES_Y6_Gold_v1_derred.fits\", 1.19863, 0.83734, ngp, sgp, param['results_path'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below reads the position, calculates the extinction using the previous function and <br>\n",
    "correct the aparent magnitude (top of the Galaxy), filter the stars for magnitude and color ranges, <br> \n",
    "and writes a file with the original position of the stars and corrected magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of dwarf galaxies and globular clusters\n",
    "\n",
    "In fact, the dwarf galaxies and globular clusters are very similar in terms of stellar populations. Dwarf galaxies\n",
    "have a half-light radius larger than globular clusters (given the amount of dark matter) with the same absolute magnitude. The code below simulates stars using a Kroupa or Salpeter IMF, and an exponential radius for the 2D distribution of stars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the properties of clusters based on properties stated above. Writting to file 'objects.dat'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RA_pix, DEC_pix, r_exp, ell, pa, dist, mass, mM, hp_sample_un = gen_clus_file(\n",
    "    param['ra_min'],\n",
    "    param['ra_max'],\n",
    "    param['dec_min'],\n",
    "    param['dec_max'],\n",
    "    param['nside_ini'],\n",
    "    param['border_extract'],\n",
    "    param['mM_min'],\n",
    "    param['mM_max'],\n",
    "    param['log10_rexp_min'],\n",
    "    param['log10_rexp_max'],\n",
    "    param['log10_mass_min'],\n",
    "    param['log10_mass_max'],\n",
    "    param['ell_min'],\n",
    "    param['ell_max'],\n",
    "    param['pa_min'],\n",
    "    param['pa_max'],\n",
    "    param['results_path']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dist stars\n",
    "Reading data from magnitude and errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag1_, err1_, err2_ = read_error(param['file_error'], 0.015, 0.015)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now simulating the clusters using 'faker' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def faker_app(N_stars_cmd, frac_bin, IMF_author, x0, y0, rexp, ell_, pa, dist, hpx, output_path):\n",
    "\n",
    "    global param\n",
    "\n",
    "    faker(\n",
    "        N_stars_cmd,\n",
    "        frac_bin,\n",
    "        IMF_author,\n",
    "        x0,\n",
    "        y0,\n",
    "        rexp,\n",
    "        ell_,\n",
    "        pa,\n",
    "        dist,\n",
    "        hpx,\n",
    "        param['cmin'],\n",
    "        param['cmax'],\n",
    "        param['mmin'],\n",
    "        param['mmax'],\n",
    "        mag1_,\n",
    "        err1_,\n",
    "        err2_,\n",
    "        param['file_iso'],\n",
    "        output_path\n",
    "    )\n",
    "\n",
    "\n",
    "# Diretório dos arquivo _clus.dat gerados pela faker.\n",
    "fake_clus_path = param['results_path'] + '/fake_clus'\n",
    "\n",
    "futures = list()\n",
    "\n",
    "# Cria uma Progressbar (Opcional)\n",
    "with tqdm(total=len(hp_sample_un), file=sys.stdout) as pbar:\n",
    "    pbar.set_description(\"Submit Parsls Tasks\")\n",
    "\n",
    "    # Submissão dos Jobs Parsl\n",
    "    for i in range(len(hp_sample_un)):\n",
    "        # Estimating the number of stars in cmd dividing mass by mean mass\n",
    "        N_stars_cmd = int(mass[i] / mean_mass)\n",
    "        # os.register_at_fork(after_in_child=lambda: _get_font.cache_clear())\n",
    "        futures.append(\n",
    "            faker_app(\n",
    "                N_stars_cmd,\n",
    "                param['frac_bin'],\n",
    "                param['IMF_author'],\n",
    "                RA_pix[i],\n",
    "                DEC_pix[i],\n",
    "                r_exp[i],\n",
    "                ell[i],\n",
    "                pa[i],\n",
    "                dist[i],\n",
    "                hp_sample_un[i],\n",
    "                output_path=fake_clus_path\n",
    "            )\n",
    "        )\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "# Progressbar para acompanhar as parsl.tasks.\n",
    "print(\"Tasks Done:\")\n",
    "with tqdm(total=len(futures), file=sys.stdout) as pbar2:\n",
    "    # is_done é um array contendo True ou False para cada task\n",
    "    # is_done.count(True) retorna a quantidade de tasks que já terminaram.\n",
    "    is_done = list()\n",
    "    done_count = 0\n",
    "    while is_done.count(True) != len(futures):\n",
    "        is_done = list()\n",
    "        for f in futures:\n",
    "            is_done.append(f.done())\n",
    "\n",
    "        # Só atualiza a pbar se o valor for diferente.\n",
    "        if is_done.count(True) != done_count:\n",
    "            done_count = is_done.count(True)\n",
    "            # Reset é necessário por que a quantidade de iterações\n",
    "            # é maior que a quantidade de jobs.\n",
    "            pbar2.reset(total=len(futures))\n",
    "            # Atualiza a pbar\n",
    "            pbar2.update(done_count)\n",
    "\n",
    "        if done_count < len(futures):\n",
    "            sleep(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now functions to join catalogs of simulated clusters and field stars, and to estimate signal-to-noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le os arquivos _clus.dat do diretório \"result/fake_clus\"\n",
    "# Gera o arquivo \"result/<survey>_mockcat_for_detection.fits\"\n",
    "mockcat = join_cat(\n",
    "    param['ra_min'],\n",
    "    param['ra_max'],\n",
    "    param['dec_min'],\n",
    "    param['dec_max'],\n",
    "    hp_sample_un,\n",
    "    param['survey'],\n",
    "    RA,\n",
    "    DEC,\n",
    "    MAG_G,\n",
    "    MAG_R,\n",
    "    MAGERR_G,\n",
    "    MAGERR_R,\n",
    "    param['nside_ini'],\n",
    "    param['mmax'],\n",
    "    param['mmin'],\n",
    "    param['cmin'],\n",
    "    param['cmax'],\n",
    "    input_path=fake_clus_path,\n",
    "    output_path=param['results_path'])\n",
    "print(mockcat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary, split the catalog with simulated clusters into many files according HP schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(param['hpx_cats_path'], exist_ok=True)\n",
    "ipix_cats = split_files(mockcat, 'ra', 'dec',\n",
    "                        param['nside_ini'], param['hpx_cats_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_clus_feat = write_sim_clus_features(\n",
    "    mockcat, hp_sample_un, param['nside_ini'], mM, output_path=param['results_path'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge both files in a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_file_results(param['results_path'], \"star_clusters_simulated.dat\",\n",
    "                  sim_clus_feat, 'results/objects.dat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "A few plots to characterize the simulated clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ga_sim.plot import (\n",
    "    general_plots,\n",
    "    plot_ftp,\n",
    "    plots_ang_size,\n",
    "    plots_ref,\n",
    "    plot_err,\n",
    "    plot_clusters_clean\n",
    ")\n",
    "\n",
    "general_plots(param['star_clusters_simulated'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot footprint map to check area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpx_ftp = param['results_path'] + \"/ftp_4096_nest.fits\"\n",
    "\n",
    "plot_ftp(hpx_ftp, param['star_clusters_simulated'],\n",
    "         mockcat, param['ra_max'], param['ra_min'], param['dec_min'], param['dec_max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório onde estão os arquivo _clus.dat\n",
    "plots_ang_size(param['star_clusters_simulated'], param['results_path'],\n",
    "               param['mmin'], param['mmax'], param['cmin'], param['cmax'],\n",
    "               param['output_plots'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_ref(FeH_iso, param['star_clusters_simulated'], param['output_plots'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting errors in main magnitude band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots to analyze the simulated clusters.\n",
    "plot_err(mockcat, param['output_plots'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stars close to each other\n",
    "\n",
    "Now, we have to remove stars that are not detected in the pipeline of detection of the survey. In principle, the software used by detect sources is SExtractor, which parameter deblend is set to blend sources very close to each other.\n",
    "\n",
    "To remove sources close to each other, the approach below (or the function on that) read catalogs from ipixels (HealPixels).\n",
    "To each star the distance to all sources are calculated. If the second minimum distance (the first one is zero, since it is the iteration of the stars with itself) is less than the distance defined as a parameter of the function, the star is not listed in the filtered catalog.\n",
    "The function runs in parallel, in order to run faster using all the cores of node.\n",
    "\n",
    "Firstly, setting the string to read position of stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def clean_input_cat_dist_app(file_name, ra_str, dec_str, min_dist_arcsec):\n",
    "\n",
    "    clean_input_cat_dist(\n",
    "        file_name,\n",
    "        ra_str,\n",
    "        dec_str,\n",
    "        min_dist_arcsec\n",
    "    )\n",
    "\n",
    "\n",
    "futures = list()\n",
    "\n",
    "# Cria uma Progressbar (Opcional)\n",
    "with tqdm(total=len(ipix_cats), file=sys.stdout) as pbar:\n",
    "    pbar.set_description(\"Submit Parsls Tasks\")\n",
    "\n",
    "    # Submissão dos Jobs Parsl\n",
    "    for i in ipix_cats:\n",
    "        futures.append(\n",
    "            clean_input_cat_dist_app(\n",
    "                i, param['ra_str'], param['dec_str'], param['min_dist_arcsec'])\n",
    "        )\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "# Espera todas as tasks Parsl terminarem\n",
    "# Este loop fica monitarando as parsl.futures\n",
    "# Até que todas tenham status done.\n",
    "# Esse bloco todo é opcional\n",
    "\n",
    "print(\"Tasks Done:\")\n",
    "with tqdm(total=len(futures), file=sys.stdout) as pbar2:\n",
    "    # is_done é um array contendo True ou False para cada task\n",
    "    # is_done.count(True) retorna a quantidade de tasks que já terminaram.\n",
    "    is_done = list()\n",
    "    done_count = 0\n",
    "    while is_done.count(True) != len(futures):\n",
    "        is_done = list()\n",
    "        for f in futures:\n",
    "            is_done.append(f.done())\n",
    "\n",
    "        # Só atualiza a pbar se o valor for diferente.\n",
    "        if is_done.count(True) != done_count:\n",
    "            done_count = is_done.count(True)\n",
    "            # Reset é necessário por que a quantidade de iterações\n",
    "            # é maior que a quantidade de jobs.\n",
    "            pbar2.reset(total=len(futures))\n",
    "            # Atualiza a pbar\n",
    "            pbar2.update(done_count)\n",
    "\n",
    "        if done_count < len(futures):\n",
    "            sleep(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering stars in HealPixels, join all the HP into a single catalog called final cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipix_clean_cats = [i.split('.')[0] + '_clean_dist.fits' for i in ipix_cats]\n",
    "join_cats_clean(ipix_clean_cats,\n",
    "                param['final_cat'], param['ra_str'], param['dec_str'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot clusters comparing filtered and not filtered stars in each cluster. The region sampled is the center of the cluster where the crowding is more intense.</br>\n",
    "Below the clusters with stars were filtered by max distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters_clean(ipix_cats, ipix_clean_cats,\n",
    "                    param['nside_ini'], param['ra_str'], param['dec_str'], 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ga_sim",
   "language": "python",
   "name": "ga_sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
