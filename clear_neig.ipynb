{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3569f49f-f3a1-4009-b516-398ada3ac7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f43ede3a4f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import astropy\n",
    "import astropy.io.fits as fits\n",
    "from astropy.io.fits import getdata\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import healpy as hp\n",
    "import os\n",
    "import sys\n",
    "import parsl\n",
    "from parsl import python_app, bash_app\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "parsl.clear()\n",
    "parsl.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329ba3aa-b40b-4043-8dd1-bb14d0eb6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_cats(ipix_cats, output_file, ra_str, dec_str):\n",
    "    \"\"\"This function writes a single Fits file catalog gathering\n",
    "    data read in all the ipix_cats.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ipix_cats : list\n",
    "        List of ipix FITS files catalogs.\n",
    "    output_file : str\n",
    "        File name with all data from ipix cats.\n",
    "    ra_str : str\n",
    "        Label of RA coordinate.\n",
    "    dec_str : str\n",
    "        Label of DEC coordinate.\n",
    "    \"\"\"\n",
    "    t = Table.read(ipix_cats[0])\n",
    "    label_columns = t.colnames\n",
    "    t_format = []\n",
    "    for i in label_columns:\n",
    "        t_format.append(t[i].info.dtype)\n",
    "\n",
    "    for i, j in enumerate(ipix_cats):\n",
    "        if i == 0:\n",
    "            data = getdata(j)\n",
    "            all_data = data\n",
    "        else:\n",
    "            data = getdata(j)\n",
    "            all_data = np.concatenate((all_data, data))\n",
    "\n",
    "    col = [i for i in range(len(label_columns))]\n",
    "\n",
    "    for i, j in enumerate(label_columns):\n",
    "        col[i] = fits.Column(\n",
    "            name=j, format=t_format[i], array=all_data[label_columns[i]])\n",
    "    cols = fits.ColDefs([col[i] for i in range(len(label_columns))])\n",
    "    tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "    tbhdu.writeto(output_file, overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "def split_files(in_file, ra_str, dec_str, nside, path):\n",
    "    \"\"\"This function split a main file into small catalogs, based on\n",
    "    HealPix ipix files, with nside=nside.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_file : str\n",
    "        Input file.\n",
    "    ra_str : str\n",
    "        Label of RA coordinate.\n",
    "    dec_str : str\n",
    "        Label of DEC coordinate.\n",
    "    nside : int\n",
    "        Nside to split small catalogs.\n",
    "    path : str\n",
    "        Path to output files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Name and path of output files.\n",
    "    \"\"\"\n",
    "\n",
    "    os.system('mkdir -p ' + path)\n",
    "\n",
    "    data = getdata(in_file)\n",
    "    t = Table.read(in_file)\n",
    "    label_columns = t.colnames\n",
    "    t_format = []\n",
    "    for i in label_columns:\n",
    "        t_format.append(t[i].info.dtype)\n",
    "    HPX = hp.ang2pix(nside, data[ra_str],\n",
    "                     data[dec_str], nest=True, lonlat=True)\n",
    "\n",
    "    HPX_un = np.unique(HPX)\n",
    "\n",
    "    for j in HPX_un:\n",
    "        cond = (HPX == j)\n",
    "        data_ = data[cond]\n",
    "        col = [i for i in range(len(label_columns))]\n",
    "\n",
    "        for i in range(len(label_columns)):\n",
    "            col[i] = fits.Column(\n",
    "                name=label_columns[i], format=t_format[i], array=data_[label_columns[i]])\n",
    "        cols = fits.ColDefs([col[i] for i in range(len(label_columns))])\n",
    "        tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "        tbhdu.writeto(path + str(j) + '.fits', overwrite=True)\n",
    "\n",
    "    return [path + str(i) + '.fits' for i in HPX_un]\n",
    "\n",
    "\n",
    "@python_app\n",
    "def clean_input_cat(file_name, ra_str, dec_str, nside):\n",
    "    \"\"\" This function removes all the stars that resides in the same ipix with\n",
    "    nside = nside. This is done to simulate the features of real catalogs based on\n",
    "    detections from SExtractor, where objects very close to each other are\n",
    "    interpreted as a single object. That is specially significant to\n",
    "    stellar clusters, where the stellar crowding in images creates a single\n",
    "    object in cluster's center, but many star in the periphery.\n",
    "    This function calculates the counts in each ipix with nside (usually > 2 ** 15)\n",
    "    and removes ALL of stars that resides in the same pixel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        Name of input file.\n",
    "    ra_str : str\n",
    "        Label for RA coordinate.\n",
    "    dec_str : str\n",
    "        Label for DEC coordinate.\n",
    "    nside : int\n",
    "        Nside to be populated.\n",
    "    \"\"\"\n",
    "\n",
    "    output_file = file_name.split('.')[0] + '_clean.fits'\n",
    "\n",
    "    data = getdata(file_name)\n",
    "    t = Table.read(file_name)\n",
    "    label_columns = t.colnames\n",
    "    t_format = []\n",
    "    for i in label_columns:\n",
    "        t_format.append(t[i].info.dtype)\n",
    "    HPX = hp.ang2pix(nside, data[ra_str],\n",
    "                     data[dec_str], nest=True, lonlat=True)\n",
    "\n",
    "    HPX_idx_sort = np.argsort(HPX)\n",
    "\n",
    "    HPX_sort = [HPX[i] for i in HPX_idx_sort]\n",
    "    data_sort = data[HPX_idx_sort]\n",
    "\n",
    "    a, HPX_idx = np.unique(HPX_sort, return_inverse=True)\n",
    "\n",
    "    # original order not preserved!\n",
    "    HPX_un, HPX_counts = np.unique(HPX_sort, return_counts=True)\n",
    "\n",
    "    HPX_single_star_pix = [\n",
    "        j for i, j in enumerate(HPX_un) if HPX_counts[i] < 2]\n",
    "\n",
    "    data_clean = np.array([data_sort[:][i] for i, j in enumerate(HPX_idx) if\n",
    "                           HPX_un[j] in HPX_single_star_pix])\n",
    "\n",
    "    col = [i for i in range(len(label_columns))]\n",
    "\n",
    "    for i, j in enumerate(label_columns):\n",
    "        col[i] = fits.Column(\n",
    "            name=label_columns[i], format=t_format[i], array=data_clean[:, i])\n",
    "    cols = fits.ColDefs([col[i] for i in range(len(label_columns))])\n",
    "    tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "    tbhdu.writeto(output_file, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b6fcc2-1ae0-4352-b7a8-7e98967895e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cat = 'results/des_mockcat_for_detection.fits'\n",
    "ra_str, dec_str = 'ra', 'dec'\n",
    "path_split = 'results/hpx_cats/'\n",
    "final_cat = 'cat_clean.fits'\n",
    "nside = 64\n",
    "\n",
    "ipix_cats = split_files(input_cat, ra_str, dec_str, nside, path_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e75f380-ad60-4ce5-964f-df6627199341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit Parsls Tasks: 100%|██████████| 135/135 [00:00<00:00, 744.19it/s]\n",
      "Tasks Done:\n",
      " 21%|██▏       | 29/135 [00:21<01:20,  1.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     pbar2\u001b[38;5;241m.\u001b[39mupdate(done_count)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(futures):\n\u001b[0;32m---> 41\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "futures = list()\n",
    "\n",
    "# Cria uma Progressbar (Opcional)\n",
    "with tqdm(total=len(ipix_cats), file=sys.stdout) as pbar:\n",
    "    pbar.set_description(\"Submit Parsls Tasks\")\n",
    "\n",
    "    # Submissão dos Jobs Parsl\n",
    "    for i in ipix_cats:\n",
    "        futures.append(\n",
    "            clean_input_cat(i, ra_str, dec_str, 2 ** 17)\n",
    "        )\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "# Espera todas as tasks Parsl terminarem\n",
    "# Este loop fica monitarando as parsl.futures\n",
    "# Até que todas tenham status done.\n",
    "# Esse bloco todo é opcional\n",
    "\n",
    "print(\"Tasks Done:\")\n",
    "with tqdm(total=len(futures), file=sys.stdout) as pbar2:\n",
    "    # is_done é um array contendo True ou False para cada task\n",
    "    # is_done.count(True) retorna a quantidade de tasks que já terminaram.\n",
    "    is_done = list()\n",
    "    done_count = 0\n",
    "    while is_done.count(True) != len(futures):\n",
    "        is_done = list()\n",
    "        for f in futures:\n",
    "            is_done.append(f.done())\n",
    "\n",
    "        # Só atualiza a pbar se o valor for diferente.\n",
    "        if is_done.count(True) != done_count:\n",
    "            done_count = is_done.count(True)\n",
    "            # Reset é necessário por que a quantidade de iterações\n",
    "            # é maior que a quantidade de jobs.\n",
    "            pbar2.reset(total=len(futures))\n",
    "            # Atualiza a pbar\n",
    "            pbar2.update(done_count)\n",
    "\n",
    "        if done_count < len(futures):\n",
    "            sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c792bc8b-4517-4834-9338-7e05ec592bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipix_clean_cats = [i.split('.')[0] + '_clean.fits' for i in ipix_cats]\n",
    "join_cats(ipix_clean_cats, final_cat, ra_str, dec_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8c309-0fd3-4a20-ae8c-30d46d9840aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ipix = len(ipix_clean_cats)\n",
    "\n",
    "ipix = [int((i.split('/')[-1]).split('.')[0]) for i in ipix_cats]\n",
    "\n",
    "ra_cen, dec_cen = hp.pix2ang(nside, ipix, nest=True, lonlat=True)\n",
    "half_size_plot = 0.01\n",
    "fig, ax = plt.subplots(len_ipix, 4, figsize=(18, 4 * len_ipix))\n",
    "j = 0\n",
    "for i in range(len_ipix):\n",
    "    line = int(j / 4)\n",
    "    col = int(j % 4)\n",
    "    data = fits.getdata(ipix_cats[i])\n",
    "    RA_orig = data[ra_str]\n",
    "    DEC_orig = data[dec_str]\n",
    "    if len(RA_orig[(RA_orig < ra_cen[i] + half_size_plot)&(RA_orig > ra_cen[i] - half_size_plot)&\\\n",
    "                   (DEC_orig < dec_cen[i] + half_size_plot)&(DEC_orig > dec_cen[i] - half_size_plot)]) > 10.:\n",
    "        data = fits.getdata(ipix_clean_cats[i])\n",
    "        RA = data[ra_str]\n",
    "        DEC = data[dec_str]\n",
    "        ax[line, col].scatter(RA_orig, DEC_orig, edgecolor='b', color='None', s=20)\n",
    "        ax[line, col].set_xlim([ra_cen[i] + half_size_plot, ra_cen[i] - half_size_plot])\n",
    "        ax[line, col].set_ylim([dec_cen[i] - half_size_plot, dec_cen[i] + half_size_plot])\n",
    "        ax[line, col].scatter(RA, DEC, color='r', s=2)\n",
    "        ax[line, col].set_xlim([ra_cen[i] + half_size_plot, ra_cen[i] - half_size_plot])\n",
    "        ax[line, col].set_ylim([dec_cen[i] - half_size_plot, dec_cen[i] + half_size_plot])\n",
    "        ax[line, col].set_xticks([])\n",
    "        ax[line, col].set_yticks([])\n",
    "        ax[line, col].set_title(str(ipix[i]), x=0.5, y=0.6, fontsize=8)\n",
    "        j += 1\n",
    "plt.suptitle('Blue: original, Red: filtered stars; Each poststamp has {:.2f} arcmin'.format(2. * 60. * half_size_plot))\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701e02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ga_sim",
   "language": "python",
   "name": "ga_sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
