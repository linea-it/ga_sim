{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3569f49f-f3a1-4009-b516-398ada3ac7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7facbc5fd2e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import astropy\n",
    "import astropy.io.fits as fits\n",
    "from astropy.io.fits import getdata\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import healpy as hp\n",
    "import os\n",
    "import sys\n",
    "import parsl\n",
    "from parsl import python_app, bash_app\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "parsl.clear()\n",
    "parsl.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329ba3aa-b40b-4043-8dd1-bb14d0eb6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_cat(data, label_columns, t_format, output_file):\n",
    "    \"\"\" This function writes a single Fits file catalog for data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        Data to be written in output_file.\n",
    "    label_columns : list\n",
    "        Label of columns to be written in fits file.\n",
    "    t_format : list\n",
    "        Format of data to be written in fits file.\n",
    "    output_file : str\n",
    "        Name of output file.\n",
    "    \"\"\"\n",
    "    col = [i for i in range(len(label_columns))]\n",
    "\n",
    "    for i, j in enumerate(label_columns):\n",
    "        col[i] = fits.Column(\n",
    "            name=label_columns[i], format=t_format[i], array=data[:, i])\n",
    "    cols = fits.ColDefs([col[i] for i in range(len(label_columns))])\n",
    "    tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "    tbhdu.writeto(output_file, overwrite=True)\n",
    "\n",
    "\n",
    "def split_files(in_file, ra_str, dec_str, nside, path):\n",
    "    \"\"\"This function split a main file into many small catalogs, based on\n",
    "    HealPix ipix files, with nside=nside.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_file : str\n",
    "        Input file.\n",
    "    ra_str : str\n",
    "        Label of RA coordinate.\n",
    "    dec_str : str\n",
    "        Label of DEC coordinate.\n",
    "    nside : int\n",
    "        Nside to split small catalogs.\n",
    "    path : str\n",
    "        Path to output files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Name and path of output files.\n",
    "    \"\"\"\n",
    "\n",
    "    os.system('mkdir -p ' + path)\n",
    "\n",
    "    data = getdata(in_file)\n",
    "    t = Table.read(in_file)\n",
    "    label_columns = t.colnames\n",
    "    t_format = []\n",
    "    for i in label_columns:\n",
    "        t_format.append(t[i].info.dtype)\n",
    "    HPX = hp.ang2pix(nside, data[ra_str],\n",
    "                     data[dec_str], nest=True, lonlat=True)\n",
    "\n",
    "    HPX_un = np.unique(HPX)\n",
    "\n",
    "    for i, j in enumerate(HPX_un):\n",
    "        cond = (HPX == j)\n",
    "        data_ = data[cond]\n",
    "        col = [i for i in range(len(label_columns))]\n",
    "\n",
    "        for i, j in enumerate(label_columns):\n",
    "            col[i] = fits.Column(\n",
    "                name=label_columns[i], format=t_format[i], array=data_[label_columns[i]])\n",
    "        cols = fits.ColDefs([col[i] for i in range(len(label_columns))])\n",
    "        tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "        tbhdu.writeto(path + str(j) + '.fits', overwrite=True)\n",
    "\n",
    "    ipix_cats = [path + str(j) + '.fits' for j in HPX_un]\n",
    "    return ipix_cats\n",
    "\n",
    "\n",
    "@ python_app\n",
    "def clean_input_cat(file_name, ra_str, dec_str, nside):\n",
    "    \"\"\" This function removes all the stars that resides in the same ipix with\n",
    "    nside = nside. This is done to simulate the features of real catalogs based on\n",
    "    detections from SExtractor, where objects very close to each other are interpreted\n",
    "    as a single object. That is specially significant to stellar clusters, where the\n",
    "    stellar crowding in images creates a single object in cluster's center, but many\n",
    "    star in the periphery.\n",
    "    This function calculates the counts in each ipix with nside (usually > 2 ** 15)\n",
    "    and removes ALL of stars that resides in the same pixel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        Name of input file.\n",
    "    ra_str : str\n",
    "        Label for RA coordinate.\n",
    "    dec_str : str\n",
    "        Label for DEC coordinate.\n",
    "    nside : int\n",
    "        Nside to be populated.\n",
    "    \"\"\"\n",
    "\n",
    "    output_file = file_name.split('.')[0] + '_clean.fits'\n",
    "\n",
    "    data = getdata(file_name)\n",
    "    t = Table.read(file_name)\n",
    "    label_columns = t.colnames\n",
    "    t_format = []\n",
    "    for i in label_columns:\n",
    "        t_format.append(t[i].info.dtype)\n",
    "    HPX = hp.ang2pix(nside, data[ra_str],\n",
    "                     data[dec_str], nest=True, lonlat=True)\n",
    "\n",
    "    HPX_idx_sort = np.argsort(HPX)\n",
    "\n",
    "    HPX_sort = [HPX[i] for i in HPX_idx_sort]\n",
    "    data_sort = data[HPX_idx_sort]\n",
    "\n",
    "    a, HPX_idx = np.unique(HPX_sort, return_inverse=True)\n",
    "\n",
    "    # original order not preserved!\n",
    "    HPX_un, HPX_counts = np.unique(HPX_sort, return_counts=True)\n",
    "\n",
    "    HPX_single_star_pix = [\n",
    "        j for i, j in enumerate(HPX_un) if HPX_counts[i] < 2]\n",
    "\n",
    "    data_clean = np.array([data_sort[:][i] for i, j in enumerate(HPX_idx) if\n",
    "                           HPX_un[j] in HPX_single_star_pix])\n",
    "\n",
    "    col = [i for i in range(len(label_columns))]\n",
    "\n",
    "    for i, j in enumerate(label_columns):\n",
    "        col[i] = fits.Column(\n",
    "            name=label_columns[i], format=t_format[i], array=data_clean[:, i])\n",
    "        cols = fits.ColDefs([col[i] for i in range(len(label_columns))])\n",
    "    tbhdu = fits.BinTableHDU.from_columns(cols)\n",
    "    tbhdu.writeto(output_file, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b6fcc2-1ae0-4352-b7a8-7e98967895e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: invalid option -- 'r'\n",
      "Try 'mkdir --help' for more information.\n"
     ]
    }
   ],
   "source": [
    "ipix_cats = split_files('results/des_mockcat_for_detection.fits', 'ra',\n",
    "                        'dec', 64, 'results/hpx_cats/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75f380-ad60-4ce5-964f-df6627199341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit Parsls Tasks: 100%|██████████| 135/135 [00:00<00:00, 673.24it/s]\n",
      "Tasks Done:\n",
      "  0%|          | 0/135 [00:00<?, ?it/s]          "
     ]
    }
   ],
   "source": [
    "futures = list()\n",
    "\n",
    "# Cria uma Progressbar (Opcional)\n",
    "with tqdm(total=len(ipix_cats), file=sys.stdout) as pbar:\n",
    "    pbar.set_description(\"Submit Parsls Tasks\")\n",
    "\n",
    "    # Submissão dos Jobs Parsl\n",
    "    for i in ipix_cats:\n",
    "        futures.append(\n",
    "            clean_input_cat(i, 'ra', 'dec', 2**17)\n",
    "        )\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "# Espera todas as tasks Parsl terminarem\n",
    "# Este loop fica monitarando as parsl.futures\n",
    "# Até que todas tenham status done.\n",
    "# Esse bloco todo é opcional\n",
    "\n",
    "print(\"Tasks Done:\")\n",
    "with tqdm(total=len(futures), file=sys.stdout) as pbar2:\n",
    "    # is_done é um array contendo True ou False para cada task\n",
    "    # is_done.count(True) retorna a quantidade de tasks que já terminaram.\n",
    "    is_done = list()\n",
    "    done_count = 0\n",
    "    while is_done.count(True) != len(futures):\n",
    "        is_done = list()\n",
    "        for f in futures:\n",
    "            is_done.append(f.done())\n",
    "\n",
    "        # Só atualiza a pbar se o valor for diferente.\n",
    "        if is_done.count(True) != done_count:\n",
    "            done_count = is_done.count(True)\n",
    "            # Reset é necessário por que a quantidade de iterações\n",
    "            # é maior que a quantidade de jobs.\n",
    "            pbar2.reset(total=len(futures))\n",
    "            # Atualiza a pbar\n",
    "            pbar2.update(done_count)\n",
    "\n",
    "        if done_count < len(futures):\n",
    "            sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792bc8b-4517-4834-9338-7e05ec592bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cat(data_clean, label_columns, t_format, 'cat_clean.fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8c309-0fd3-4a20-ae8c-30d46d9840aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a few plots showing the results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ga_sim",
   "language": "python",
   "name": "ga_sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
